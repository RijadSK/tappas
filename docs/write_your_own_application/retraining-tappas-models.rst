.. _retraining_tappas_models:

========================
Retraining TAPPAS Models
========================

Instructions
------------

If you wish to use a TAPPAS pipeline/demo with your own model, the easiest solution is:

#. Read the relevant TAPPAS pipeline/demo README page:
    - It lists the ModelZoo models that are used on this pipeline
    - If Model Zoo retraining dockers are available for those models, links are given; In addition it describes how to 
      reconfigure TAPPAS for the retrained models
#. Follow the retraining docker's instructions to retrain the model with your own data
#. Follow the retraining docker's instructions to compile the network
#. Reconfigure TAPPAS scripts to run your new .hef file(s)

Notes
-----
- Easy post-processing JSON reconfiguration is currently only available for YOLO architecures. For other architectures,
  recreating post-processing .so file is required. The relevant code and header files are mentioned on the README pages.
- Models that use on-chip RGBX->RGB layers does not appear yet on the ModelZoo. Therefore, many models that are used
  for iMX demos (and others; see on the README of each app) should be added those layers manually to create models that will fit TAPPAS:
  
  - Use the non-rgbx network from the above table for retraining and compilation, with one simple modification - 
    On the model alls file (on `hailo_model_zoo/cfg/alls <https://github.com/hailo-ai/hailo_model_zoo/tree/master/hailo_model_zoo/cfg/alls>`_),
    add **right after normalization command**:
    
    .. code::

        reshape_rgb = input_conversion(input_layer1, tf_rgbx_to_hailo_rgb)